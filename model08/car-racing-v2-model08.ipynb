{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8eea6db-85c6-41ec-86e6-c33876b5cd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:23: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:24: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:25: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:28: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  if hasattr(pil_image, 'HAMMING'):\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:30: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  if hasattr(pil_image, 'BOX'):\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  if hasattr(pil_image, 'LANCZOS'):\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import copy, random, os, subprocess, cv2\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow.keras import layers, models, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b986a31-fe27-454a-b700-5899f7b4cb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://etsuji-car-racing-v2/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'etsuji-car-racing-v2' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n",
      "gs://etsuji-car-racing-v2/model04/\n",
      "gs://etsuji-car-racing-v2/model05/\n",
      "gs://etsuji-car-racing-v2/model06/\n",
      "gs://etsuji-car-racing-v2/model07/\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'model08'\n",
    "BUCKET = 'gs://etsuji-car-racing-v2'\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "!gsutil mb -c regional -l us-west1 $BUCKET\n",
    "!gsutil ls $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a539d906-85d3-487e-a0d9-c111e8abbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyL1Weight(layers.Layer):\n",
    "    def __init__(self, l1=0.01, **kwargs):\n",
    "        self.filter_shape = None\n",
    "        self.l1 = l1\n",
    "        super(ApplyL1Weight, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='weights', shape=[input_shape[3]],\n",
    "                                      regularizer=regularizers.L1(self.l1))\n",
    "        self.filter_shape = input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'l1': self.l1,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs, **kwargs):\n",
    "        return inputs * self.kernel\n",
    "    \n",
    "# Base model\n",
    "class QValue:\n",
    "    def __init__(self):\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        cnn_input = layers.Input(shape=(48, 48, 3), name='cnn_input')\n",
    "        cnn1 = layers.Conv2D(16, (5, 5), padding='same',\n",
    "                             use_bias=True, activation='relu',\n",
    "                             name='cnn1')(cnn_input)\n",
    "        pool1 = layers.MaxPooling2D((2, 2), name='pool1')(cnn1)\n",
    "        cnn2 = layers.Conv2D(16, (5, 5), padding='same',\n",
    "                             use_bias=True, activation='relu',\n",
    "                             name='cnn2')(pool1)        \n",
    "        pool2 = layers.MaxPooling2D((2, 2), name='pool2')(cnn2)\n",
    "        weighted_filters = ApplyL1Weight(name='weighted_filters')(pool2)\n",
    "\n",
    "        cnn_flatten = layers.Flatten(name='flatten')(weighted_filters)\n",
    "        action_input = layers.Input(shape=(5,), name='action_input')\n",
    "        combined = layers.concatenate([cnn_flatten, action_input], name='concat')\n",
    "        hidden1 = layers.Dense(2048, activation='relu', name='dense1')(combined)\n",
    "        hidden2 = layers.Dense(1024, activation='relu', name='dense2')(hidden1)\n",
    "        hidden3 = layers.Dense(512, activation='relu', name='dense3')(hidden2)\n",
    "        q_value = layers.Dense(1, name='output')(hidden3)\n",
    "\n",
    "        model = models.Model(inputs=[cnn_input, action_input], outputs=q_value)\n",
    "        model.compile(loss='mse')\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        states = []\n",
    "        actions = []\n",
    "        for a in range(5):\n",
    "            states.append(np.array(state))\n",
    "            action_onehot = np.zeros(5)\n",
    "            action_onehot[a] = 1\n",
    "            actions.append(action_onehot)\n",
    "  \n",
    "        q_values = self.model.predict([np.array(states), np.array(actions)])\n",
    "        optimal_action = np.argmax(q_values)\n",
    "        return optimal_action, q_values[optimal_action][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07068286-6807-402a-bef9-51f6fb3bb9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " cnn_input (InputLayer)         [(None, 48, 48, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " cnn1 (Conv2D)                  (None, 48, 48, 16)   1216        ['cnn_input[0][0]']              \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 24, 24, 16)   0           ['cnn1[0][0]']                   \n",
      "                                                                                                  \n",
      " cnn2 (Conv2D)                  (None, 24, 24, 16)   6416        ['pool1[0][0]']                  \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 12, 12, 16)   0           ['cnn2[0][0]']                   \n",
      "                                                                                                  \n",
      " weighted_filters (ApplyL1Weigh  (None, 12, 12, 16)  16          ['pool2[0][0]']                  \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2304)         0           ['weighted_filters[0][0]']       \n",
      "                                                                                                  \n",
      " action_input (InputLayer)      [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " concat (Concatenate)           (None, 2309)         0           ['flatten[0][0]',                \n",
      "                                                                  'action_input[0][0]']           \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 2048)         4730880     ['concat[0][0]']                 \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 1024)         2098176     ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense3 (Dense)                 (None, 512)          524800      ['dense2[0][0]']                 \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            513         ['dense3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,362,017\n",
      "Trainable params: 7,362,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 04:20:49.701007: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-08-03 04:20:49.701058: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tensorflow-2-8-20220801-173936): /proc/driver/nvidia/version does not exist\n",
      "2022-08-03 04:20:49.702848: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "q_value = QValue()\n",
    "q_value.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db3f866-7954-4ed8-b413-edc8726dfc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_frames(o0, o1, o2):\n",
    "    gray_image0 = cv2.cvtColor(cv2.resize(o0, (48, 48)), cv2.COLOR_RGB2GRAY)\n",
    "    gray_image1 = cv2.cvtColor(cv2.resize(o1, (48, 48)), cv2.COLOR_RGB2GRAY)\n",
    "    gray_image2 = cv2.cvtColor(cv2.resize(o2, (48, 48)), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    return np.array(\n",
    "        [gray_image0.transpose(),\n",
    "         gray_image1.transpose(),\n",
    "         gray_image2.transpose()]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63e2758d-6498-41a9-af72-ee0f359fb94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode(environ, q_value, epsilon):\n",
    "    episode = []\n",
    "    o0 = environ.reset()\n",
    "    o1 = copy.deepcopy(o0)\n",
    "    o2 = copy.deepcopy(o0)\n",
    "    total_r = 0\n",
    "\n",
    "    if epsilon > 0:\n",
    "        keep_count = 3\n",
    "    else:\n",
    "        keep_count = 1\n",
    "\n",
    "    c = 0\n",
    "    while True:\n",
    "        if c % keep_count == 0: # Get new action\n",
    "            if np.random.random() < epsilon:\n",
    "                a = np.random.randint(5)\n",
    "            else:\n",
    "                a, _ = q_value.get_action(join_frames(o0, o1, o2))\n",
    "        c += 1\n",
    "        o_new, r, done, inf = environ.step(a)                \n",
    "        total_r += r\n",
    "\n",
    "        # Terminate episode when total reward becomes negative\n",
    "        if total_r < 0:\n",
    "            done = 1\n",
    "\n",
    "        if done:\n",
    "            # Terminal state is to achive more than 990 or get out of the field.\n",
    "            if total_r > 990 or r < -99:\n",
    "                episode.append((join_frames(o0, o1, o2), a, r, None))\n",
    "            break\n",
    "        else:\n",
    "            episode.append((join_frames(o0, o1, o2), a, r, join_frames(o1, o2, o_new)))\n",
    "        o0, o1, o2 = o1, o2, o_new\n",
    "\n",
    "    print('epsilon={}, episode length={}, total rewards={}'.format(epsilon, len(episode), total_r))\n",
    "    return episode, total_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a401e5d9-9703-426e-957d-92cda5a7c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(environ, q_value, epsilon, checkpoint=0):\n",
    "    if checkpoint > 0:\n",
    "        filename = 'car-racing-v2-{}-{}.hd5'.format(checkpoint, MODEL_NAME)\n",
    "        subprocess.run(['gsutil', 'cp', '{}/{}/{}'.format(BUCKET, MODEL_NAME, filename), './'])\n",
    "        print('load model {}'.format(filename))\n",
    "        q_value.model = models.load_model(filename)\n",
    "        os.remove(filename)\n",
    "\n",
    "    experience = []\n",
    "    good_experience = []\n",
    "    best_r = [-100, -100, -100]\n",
    "\n",
    "    for n in range(checkpoint + 1, checkpoint + 1000):\n",
    "        print('iteration {}'.format(n))\n",
    "\n",
    "        total_len = 0\n",
    "        if n % 3 == 0:\n",
    "            print('Testing the current performance...')\n",
    "            episode, total_r = get_episode(environ, q_value, epsilon=0)\n",
    "            with open('result.txt', 'a') as f:\n",
    "                f.write('{},{},{},{}\\n'.format(n, epsilon, len(episode), total_r))\n",
    "            filename = 'car-racing-v2-{}-{}.hd5'.format(n, MODEL_NAME)\n",
    "            q_value.model.save(filename, save_format='h5')\n",
    "            subprocess.run(['gsutil', '-m', 'cp',\n",
    "                            '{}'.format(filename), '{}/{}/'.format(BUCKET, MODEL_NAME)])\n",
    "            os.remove(filename)\n",
    "            experience += episode\n",
    "            total_len += len(episode)\n",
    "\n",
    "        while total_len < 500:\n",
    "            episode, total_r = get_episode(environ, q_value, epsilon)\n",
    "            total_len += len(episode)\n",
    "            experience += episode\n",
    "\n",
    "            # Keep the top 3 episodes\n",
    "            if total_r > min(best_r):\n",
    "                best_r = best_r[1:] + [total_r]\n",
    "                good_experience += episode\n",
    "                if len(good_experience) > 999 * 3:\n",
    "                    good_experience = good_experience[-999 * 3:]\n",
    "\n",
    "            \n",
    "        if len(experience) > 999 * 5: # remember last 5 episodes\n",
    "            experience = experience[-999 * 5:]\n",
    "\n",
    "        epsilon = (epsilon - 0.2) * 0.99 + 0.2\n",
    "\n",
    "        print('Training the model...')\n",
    "        # Use latest episode + past episodes (sampling) + top 3 episode (sampling)\n",
    "        latest_experience = experience[-total_len:]\n",
    "        past_experience = experience[:-total_len]\n",
    "        examples = latest_experience + \\\n",
    "            random.sample(past_experience, min(len(past_experience), 999)) + \\\n",
    "            random.sample(good_experience, min(len(good_experience), 999))\n",
    "        \n",
    "        # Show some statistics\n",
    "        print('experience length={}'.format(len(experience)))\n",
    "        print('number of examples={}'.format(len(examples)))\n",
    "        print('best total reward = ', best_r)\n",
    "        np.random.shuffle(examples)\n",
    "                        \n",
    "        states, actions, labels = [], [], []\n",
    "        for state, a, r, state_new in examples:\n",
    "            states.append(np.array(state))\n",
    "\n",
    "            action_onehot = np.zeros(5)\n",
    "            action_onehot[a] = 1\n",
    "            actions.append(action_onehot)\n",
    "            \n",
    "            if state_new is None:   # Terminal state\n",
    "                q_new = 0\n",
    "            else:\n",
    "                _, q_new = q_value.get_action(state_new)\n",
    "            labels.append(np.array(r + q_new))\n",
    "\n",
    "        hist = q_value.model.fit(\n",
    "            [np.array(states), np.array(actions)], np.array(labels),\n",
    "            batch_size=50, epochs=10, verbose=0)\n",
    "        print('loss = {}'.format(hist.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c407f1a-ef5f-4569-bdcd-2d6197a78c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " cnn_input (InputLayer)         [(None, 48, 48, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " cnn1 (Conv2D)                  (None, 48, 48, 16)   1216        ['cnn_input[0][0]']              \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 24, 24, 16)   0           ['cnn1[0][0]']                   \n",
      "                                                                                                  \n",
      " cnn2 (Conv2D)                  (None, 24, 24, 16)   6416        ['pool1[0][0]']                  \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 12, 12, 16)   0           ['cnn2[0][0]']                   \n",
      "                                                                                                  \n",
      " weighted_filters (ApplyL1Weigh  (None, 12, 12, 16)  16          ['pool2[0][0]']                  \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2304)         0           ['weighted_filters[0][0]']       \n",
      "                                                                                                  \n",
      " action_input (InputLayer)      [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " concat (Concatenate)           (None, 2309)         0           ['flatten[0][0]',                \n",
      "                                                                  'action_input[0][0]']           \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 2048)         4730880     ['concat[0][0]']                 \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 1024)         2098176     ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense3 (Dense)                 (None, 512)          524800      ['dense2[0][0]']                 \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            513         ['dense3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,362,017\n",
      "Trainable params: 7,362,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/opt/conda/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v2\", continuous=False)\n",
    "q_value = QValue()\n",
    "q_value.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad96c84-0beb-4d87-8f78-e18aeab5bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "epsilon=1.0, episode length=361, total rewards=-0.09891696750915568\n",
      "epsilon=1.0, episode length=201, total rewards=-0.065771812080482\n",
      "Training the model...\n",
      "experience length=562\n",
      "number of examples=1124\n",
      "best total reward =  [-100, -0.09891696750915568, -0.065771812080482]\n",
      "loss = [408149.6875, 34.685325622558594, 41.809669494628906, 18.42458724975586, 11.12362289428711, 8.753081321716309, 15.194820404052734, 7.518411159515381, 11.407185554504395, 6.876156330108643]\n",
      "iteration 2\n",
      "epsilon=0.992, episode length=94, total rewards=-0.00632911392403665\n",
      "epsilon=0.992, episode length=153, total rewards=-0.07432950191567156\n",
      "epsilon=0.992, episode length=68, total rewards=-0.0034482758620619502\n",
      "epsilon=0.992, episode length=69, total rewards=-0.006993006992998846\n",
      "epsilon=0.992, episode length=76, total rewards=-0.007692307692297201\n",
      "epsilon=0.992, episode length=196, total rewards=-0.0921568627450775\n",
      "Training the model...\n",
      "experience length=1218\n",
      "number of examples=2217\n",
      "best total reward =  [-0.0034482758620619502, -0.006993006992998846, -0.007692307692297201]\n",
      "loss = [1.4704267978668213, 1.5363086462020874, 1.1311908960342407, 1.7292779684066772, 0.7513267397880554, 0.7840802669525146, 1.2350702285766602, 0.7893798351287842, 0.7081968188285828, 0.6446778178215027]\n",
      "iteration 3\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=65, total rewards=-0.02105263157894141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-3-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "- [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon=0.9840800000000001, episode length=294, total rewards=-0.08823529411758124\n",
      "epsilon=0.9840800000000001, episode length=192, total rewards=-0.007395498392272354\n",
      "Training the model...\n",
      "experience length=1769\n",
      "number of examples=2549\n",
      "best total reward =  [-0.006993006992998846, -0.007692307692297201, -0.007395498392272354]\n",
      "loss = [0.6142647862434387, 0.5402365326881409, 1.6553845405578613, 0.354451984167099, 0.48177987337112427, 0.4879624545574188, 0.48838910460472107, 0.47183340787887573, 0.4230238199234009, 0.44345706701278687]\n",
      "iteration 4\n",
      "epsilon=0.9762392000000002, episode length=145, total rewards=-0.05454545454542381\n",
      "epsilon=0.9762392000000002, episode length=137, total rewards=-0.05429553264601972\n",
      "epsilon=0.9762392000000002, episode length=185, total rewards=-0.012639405204429383\n",
      "epsilon=0.9762392000000002, episode length=141, total rewards=-0.06572438162542515\n",
      "Training the model...\n",
      "experience length=2377\n",
      "number of examples=2606\n",
      "best total reward =  [-0.006993006992998846, -0.007692307692297201, -0.007395498392272354]\n",
      "loss = [0.38669344782829285, 0.3374229669570923, 0.33129623532295227, 0.3608725965023041, 0.32479622960090637, 0.3277733027935028, 0.31883975863456726, 0.30393102765083313, 0.3823871612548828, 0.2715297043323517]\n",
      "iteration 5\n",
      "epsilon=0.9684768080000001, episode length=102, total rewards=-0.026027397260256907\n",
      "epsilon=0.9684768080000001, episode length=147, total rewards=-0.09411764705880121\n",
      "epsilon=0.9684768080000001, episode length=64, total rewards=-0.06913183279742197\n",
      "epsilon=0.9684768080000001, episode length=120, total rewards=-0.08798798798796637\n",
      "epsilon=0.9684768080000001, episode length=323, total rewards=-0.03754045307434703\n",
      "Training the model...\n",
      "experience length=3133\n",
      "number of examples=2754\n",
      "best total reward =  [-0.006993006992998846, -0.007692307692297201, -0.007395498392272354]\n",
      "loss = [0.33426520228385925, 0.2794802486896515, 0.27973487973213196, 0.2815472185611725, 0.2671070992946625, 0.268044650554657, 0.2539011538028717, 0.2583080232143402, 0.26964548230171204, 0.2608954608440399]\n",
      "iteration 6\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=129, total rewards=-0.0967741935483597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-6-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon=0.9607920399200003, episode length=139, total rewards=-0.0627177700348247\n",
      "epsilon=0.9607920399200003, episode length=119, total rewards=-0.047808764940220544\n",
      "epsilon=0.9607920399200003, episode length=436, total rewards=-0.06363636363623582\n",
      "Training the model...\n",
      "experience length=3956\n",
      "number of examples=2821\n",
      "best total reward =  [-0.006993006992998846, -0.007692307692297201, -0.007395498392272354]\n",
      "loss = [0.30184879899024963, 0.2755516469478607, 0.27085748314857483, 0.26630309224128723, 0.2544651925563812, 0.26254957914352417, 0.25063762068748474, 0.24511770904064178, 0.2605138421058655, 0.2512945532798767]\n",
      "iteration 7\n",
      "epsilon=0.9531841195208004, episode length=208, total rewards=-0.06666666666661958\n",
      "epsilon=0.9531841195208004, episode length=92, total rewards=-0.06923076923075233\n",
      "epsilon=0.9531841195208004, episode length=125, total rewards=-0.06081504702193219\n",
      "epsilon=0.9531841195208004, episode length=62, total rewards=-0.06947040498441859\n",
      "epsilon=0.9531841195208004, episode length=110, total rewards=-0.029889298892965516\n",
      "Training the model...\n",
      "experience length=4553\n",
      "number of examples=2595\n",
      "best total reward =  [-0.006993006992998846, -0.007692307692297201, -0.007395498392272354]\n",
      "loss = [0.22930675745010376, 0.22790400683879852, 0.23496834933757782, 0.21909542381763458, 0.21217191219329834, 0.20775675773620605, 0.20607204735279083, 0.19304105639457703, 0.19730287790298462, 0.18875259160995483]\n",
      "iteration 8\n",
      "epsilon=0.9456522783255925, episode length=100, total rewards=-0.09999999999999365\n",
      "epsilon=0.9456522783255925, episode length=177, total rewards=-0.006405693950143759\n",
      "epsilon=0.9456522783255925, episode length=358, total rewards=-0.057706093189860086\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2633\n",
      "best total reward =  [-0.007692307692297201, -0.007395498392272354, -0.006405693950143759]\n",
      "loss = [0.2659686803817749, 0.24632152915000916, 0.23504620790481567, 0.21500371396541595, 0.22854454815387726, 0.21716342866420746, 0.21950744092464447, 0.2011609822511673, 0.21602682769298553, 0.2020866572856903]\n",
      "iteration 9\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=243, total rewards=-0.009756097560907423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-9-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "- [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon=0.9381957555423366, episode length=106, total rewards=-0.09929328621906852\n",
      "epsilon=0.9381957555423366, episode length=196, total rewards=-0.0921568627450624\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2543\n",
      "best total reward =  [-0.007692307692297201, -0.007395498392272354, -0.006405693950143759]\n",
      "loss = [0.2703229486942291, 0.24721290171146393, 0.24391482770442963, 0.229780375957489, 0.21262231469154358, 0.21273629367351532, 0.20505139231681824, 0.21652352809906006, 0.2032577246427536, 0.21023660898208618]\n",
      "iteration 10\n",
      "epsilon=0.9308137979869133, episode length=711, total rewards=-0.013559322033995985\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2709\n",
      "best total reward =  [-0.007692307692297201, -0.007395498392272354, -0.006405693950143759]\n",
      "loss = [0.37331441044807434, 0.3393740653991699, 0.3177172541618347, 0.30817708373069763, 0.3014465868473053, 0.2936227321624756, 0.2964954376220703, 0.2707340121269226, 0.2723509669303894, 0.26909372210502625]\n",
      "iteration 11\n",
      "epsilon=0.9235056600070441, episode length=182, total rewards=-0.06291793313068639\n",
      "epsilon=0.9235056600070441, episode length=126, total rewards=-0.0015873015872955587\n",
      "epsilon=0.9235056600070441, episode length=415, total rewards=-0.05697329376845972\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2721\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.2804294228553772, 0.2735322415828705, 0.23431503772735596, 0.22732017934322357, 0.2308851182460785, 0.24548690021038055, 0.21301540732383728, 0.2098882645368576, 0.20333732664585114, 0.20371297001838684]\n",
      "iteration 12\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=871, total rewards=-0.07878787878873195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-12-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2869\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.3564794659614563, 0.3118208348751068, 0.3169439733028412, 0.2849785089492798, 0.27095887064933777, 0.26540669798851013, 0.2655327022075653, 0.25878870487213135, 0.256984144449234, 0.2440417855978012]\n",
      "iteration 13\n",
      "epsilon=0.9091078973729041, episode length=206, total rewards=-0.01034482758620145\n",
      "epsilon=0.9091078973729041, episode length=86, total rewards=-0.02947976878611344\n",
      "epsilon=0.9091078973729041, episode length=180, total rewards=-0.08198198198193585\n",
      "epsilon=0.9091078973729041, episode length=105, total rewards=-0.07368421052631047\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2575\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.32605743408203125, 0.2891591489315033, 0.2544383406639099, 0.2365403175354004, 0.24487560987472534, 0.2275358885526657, 0.21533721685409546, 0.22084710001945496, 0.1946919560432434, 0.1999916136264801]\n",
      "iteration 14\n",
      "epsilon=0.902016818399175, episode length=514, total rewards=-0.029411764705730564\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2512\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.3980327248573303, 0.31160768866539, 0.2872721254825592, 0.2687039077281952, 0.2718944847583771, 0.2662478983402252, 0.2646607756614685, 0.23826710879802704, 0.24271370470523834, 0.20015737414360046]\n",
      "iteration 15\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=161, total rewards=-0.018770226537175833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-15-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon=0.8949966502151834, episode length=93, total rewards=-0.054205607476629725\n",
      "epsilon=0.8949966502151834, episode length=307, total rewards=-0.08327645051185262\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2559\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.406855970621109, 0.33657950162887573, 0.3177379369735718, 0.28043031692504883, 0.2468646615743637, 0.2419213205575943, 0.239830881357193, 0.22241351008415222, 0.22950196266174316, 0.19739623367786407]\n",
      "iteration 16\n",
      "epsilon=0.8880466837130316, episode length=142, total rewards=-0.06512455516012516\n",
      "epsilon=0.8880466837130316, episode length=714, total rewards=-0.0714285714283378\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2854\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.44720742106437683, 0.33948397636413574, 0.3258145749568939, 0.2981969118118286, 0.28645631670951843, 0.2732222378253937, 0.24472676217556, 0.2485131025314331, 0.22578799724578857, 0.21823614835739136]\n",
      "iteration 17\n",
      "epsilon=0.8811662168759014, episode length=225, total rewards=-0.04360902255635965\n",
      "epsilon=0.8811662168759014, episode length=104, total rewards=-0.010489510489502168\n",
      "epsilon=0.8811662168759014, episode length=509, total rewards=-0.09090909090893473\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2836\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.43257105350494385, 0.3342147767543793, 0.3005183935165405, 0.2633619010448456, 0.26247701048851013, 0.24090175330638885, 0.23967449367046356, 0.21822169423103333, 0.20936764776706696, 0.20027895271778107]\n",
      "iteration 18\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=764, total rewards=-93.5661870503605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-18-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "- [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2762\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [4.158449649810791, 4.029313564300537, 3.932480812072754, 3.7519350051879883, 3.557628870010376, 3.44242525100708, 3.2559170722961426, 2.4873878955841064, 2.223126173019409, 1.4806220531463623]\n",
      "iteration 19\n",
      "epsilon=0.8676110091600708, episode length=279, total rewards=-0.06703910614523179\n",
      "epsilon=0.8676110091600708, episode length=319, total rewards=-0.051118210862532765\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2596\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.45833081007003784, 0.3671867251396179, 0.3332909345626831, 0.2820863127708435, 0.2669203579425812, 0.2383360117673874, 0.2224193811416626, 0.223308727145195, 0.18780922889709473, 0.19462911784648895]\n",
      "iteration 20\n",
      "epsilon=0.8609348990684702, episode length=738, total rewards=-0.09926199261991653\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2736\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.4518682360649109, 0.3915737569332123, 0.31564804911613464, 0.2692442238330841, 0.285017728805542, 0.2456633597612381, 0.2514384090900421, 0.22966815531253815, 0.21589426696300507, 0.22675417363643646]\n",
      "iteration 21\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=186, total rewards=-0.06645962732914268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-21-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "- [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon=0.8543255500777855, episode length=383, total rewards=-0.0858237547891545\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2567\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.4841994345188141, 0.35707277059555054, 0.3283551335334778, 0.2761216461658478, 0.21259933710098267, 0.21709072589874268, 0.20886798202991486, 0.2275943011045456, 0.19707676768302917, 0.1853857785463333]\n",
      "iteration 22\n",
      "epsilon=0.8477822945770077, episode length=494, total rewards=-0.030035335688885584\n",
      "epsilon=0.8477822945770077, episode length=243, total rewards=-0.009756097560907423\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2735\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.4257183074951172, 0.32799842953681946, 0.28152963519096375, 0.25019434094429016, 0.22053903341293335, 0.21470686793327332, 0.182926207780838, 0.18335889279842377, 0.160765141248703, 0.16036364436149597]\n",
      "iteration 23\n",
      "epsilon=0.8413044716312377, episode length=487, total rewards=-0.019512195122126402\n",
      "epsilon=0.8413044716312377, episode length=313, total rewards=-0.04111498257832766\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2798\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.40906625986099243, 0.3133790194988251, 0.27681583166122437, 0.2410028725862503, 0.23055307567119598, 0.2132682055234909, 0.19298195838928223, 0.1775355190038681, 0.15585745871067047, 0.1655878871679306]\n",
      "iteration 24\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=791, total rewards=-35.14035087719073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-24-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2789\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [4.135615825653076, 3.9976394176483154, 3.943281650543213, 3.8926806449890137, 3.8688693046569824, 3.7256717681884766, 3.7530412673950195, 3.671354055404663, 3.344362497329712, 3.157416582107544]\n",
      "iteration 25\n",
      "epsilon=0.8285425126457759, episode length=680, total rewards=-0.07278911564628854\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2678\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.4974924921989441, 0.3104529082775116, 0.27913954854011536, 0.24091923236846924, 0.21612270176410675, 0.23092715442180634, 0.1758459359407425, 0.21051695942878723, 0.15606600046157837, 0.19375020265579224]\n",
      "iteration 26\n",
      "epsilon=0.8222570875193183, episode length=801, total rewards=-0.06062717770033754\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2799\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [2.9402217864990234, 1.7689756155014038, 0.6465770602226257, 0.40166693925857544, 0.87983238697052, 0.29963991045951843, 1.0110667943954468, 0.24714456498622894, 0.9550450444221497, 0.21431338787078857]\n",
      "iteration 27\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=453, total rewards=-0.09255663430448746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-27-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "- [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon=0.8160345166441252, episode length=709, total rewards=-0.054054054054291756\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=3160\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.47035494446754456, 0.3155125081539154, 0.3759278357028961, 0.25174033641815186, 0.27354368567466736, 0.22592149674892426, 0.2618136703968048, 0.18999658524990082, 0.25933513045310974, 0.17329852283000946]\n",
      "iteration 28\n",
      "epsilon=0.809874171477684, episode length=181, total rewards=-0.08405797101444823\n",
      "epsilon=0.809874171477684, episode length=312, total rewards=-0.04999999999991653\n",
      "epsilon=0.809874171477684, episode length=658, total rewards=-0.0692789968652534\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=3149\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.49571287631988525, 0.32841554284095764, 0.3452061116695404, 0.3160904347896576, 0.38422733545303345, 0.24687938392162323, 0.7698060870170593, 0.1758919358253479, 0.23190096020698547, 0.29272332787513733]\n",
      "iteration 29\n",
      "epsilon=0.8037754297629072, episode length=445, total rewards=-0.07945205479447037\n",
      "epsilon=0.8037754297629072, episode length=690, total rewards=-0.02105263157880552\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=3133\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.4597074091434479, 0.3577292561531067, 0.4367308020591736, 0.25649335980415344, 0.38670822978019714, 0.2574837803840637, 0.22968721389770508, 0.29167574644088745, 0.1835772842168808, 0.2015070915222168]\n",
      "iteration 30\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=379, total rewards=-0.06896551724154887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-30-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "- [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon=0.7977376754652781, episode length=271, total rewards=-0.08135593220332038\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2648\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.40387967228889465, 0.30479928851127625, 0.2361879199743271, 0.21110209822654724, 0.1987556368112564, 0.17172172665596008, 0.17123323678970337, 0.16941170394420624, 0.1367843598127365, 0.1480874866247177]\n",
      "iteration 31\n",
      "epsilon=0.7917602987106254, episode length=684, total rewards=-0.09609120521156211\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2682\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.4210302531719208, 0.3143061399459839, 0.2587120234966278, 0.23928846418857574, 0.2066017985343933, 0.16747109591960907, 0.18287518620491028, 0.1709468811750412, 0.15800583362579346, 0.14284391701221466]\n",
      "iteration 32\n",
      "epsilon=0.7858426957235192, episode length=430, total rewards=-0.05364238410602806\n",
      "epsilon=0.7858426957235192, episode length=203, total rewards=-0.061016949152503885\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2631\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.3949693739414215, 0.2983964681625366, 0.24525076150894165, 0.2300136834383011, 0.19331620633602142, 0.19665467739105225, 0.17254094779491425, 0.16916115581989288, 0.14043667912483215, 0.15208782255649567]\n",
      "iteration 33\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=709, total rewards=-0.054054054054632816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-33-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2707\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.40902894735336304, 0.28618934750556946, 0.25053805112838745, 0.22588852047920227, 0.21633434295654297, 0.1932445466518402, 0.17684611678123474, 0.16442115604877472, 0.17871129512786865, 0.16387516260147095]\n",
      "iteration 34\n",
      "epsilon=0.7741844260786213, episode length=317, total rewards=-0.05396825396819094\n",
      "epsilon=0.7741844260786213, episode length=797, total rewards=-0.08985507246364333\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=3112\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.47109997272491455, 0.3569785952568054, 0.31168127059936523, 0.26000675559043884, 0.2615883946418762, 0.21852107346057892, 0.20627517998218536, 0.20432059466838837, 0.19689220190048218, 0.18546034395694733]\n",
      "iteration 35\n",
      "epsilon=0.7684425818178351, episode length=682, total rewards=-0.04061433447136162\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2680\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.40280434489250183, 0.31315872073173523, 0.2621835768222809, 0.2411392480134964, 0.2058093100786209, 0.20366543531417847, 0.17236074805259705, 0.15352922677993774, 0.1566065102815628, 0.14444053173065186]\n",
      "iteration 36\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=698, total rewards=-0.05873015873070497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-36-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2696\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.4069449305534363, 0.28828945755958557, 0.2506836950778961, 0.22042174637317657, 0.20146653056144714, 0.19163882732391357, 0.16250860691070557, 0.16433797776699066, 0.15347528457641602, 0.14706140756607056]\n",
      "iteration 37\n",
      "epsilon=0.7571305744396604, episode length=459, total rewards=-0.09836065573758224\n",
      "epsilon=0.7571305744396604, episode length=761, total rewards=-0.009523809524354138\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=3218\n",
      "best total reward =  [-0.007395498392272354, -0.006405693950143759, -0.0015873015872955587]\n",
      "loss = [0.45980435609817505, 0.3286195695400238, 0.3059435486793518, 0.2538340985774994, 0.2402474284172058, 0.21626046299934387, 0.21377471089363098, 0.18976899981498718, 0.18359291553497314, 0.17592325806617737]\n",
      "iteration 38\n",
      "epsilon=0.7515592686952639, episode length=233, total rewards=-0.07638483965008569\n",
      "epsilon=0.7515592686952639, episode length=131, total rewards=-0.08524590163933188\n",
      "epsilon=0.7515592686952639, episode length=385, total rewards=-0.0035087719297035302\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2747\n",
      "best total reward =  [-0.006405693950143759, -0.0015873015872955587, -0.0035087719297035302]\n",
      "loss = [0.3884378969669342, 0.3129224479198456, 0.2450060099363327, 0.22203710675239563, 0.1997898370027542, 0.19385185837745667, 0.15696601569652557, 0.1764746457338333, 0.1376575380563736, 0.15849515795707703]\n",
      "iteration 39\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=677, total rewards=-0.058064516129591626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-39-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "- [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2675\n",
      "best total reward =  [-0.006405693950143759, -0.0015873015872955587, -0.0035087719297035302]\n",
      "loss = [0.3834252655506134, 0.2646559178829193, 0.24796733260154724, 0.21374845504760742, 0.20094630122184753, 0.19659484922885895, 0.16809512674808502, 0.16127076745033264, 0.1725781410932541, 0.14402182400226593]\n",
      "iteration 40\n",
      "epsilon=0.7405832392482283, episode length=253, total rewards=-0.0031746031745331915\n",
      "epsilon=0.7405832392482283, episode length=999, total rewards=14.814814814813758\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=3250\n",
      "best total reward =  [-0.0035087719297035302, -0.0031746031745331915, 14.814814814813758]\n",
      "loss = [0.47757869958877563, 0.3721015751361847, 0.29441168904304504, 0.2684447765350342, 0.24448691308498383, 0.22707071900367737, 0.20915746688842773, 0.19403082132339478, 0.1796119064092636, 0.1890692263841629]\n",
      "iteration 41\n",
      "epsilon=0.7351774068557462, episode length=618, total rewards=-0.010749185667738831\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2616\n",
      "best total reward =  [-0.0035087719297035302, -0.0031746031745331915, 14.814814814813758]\n",
      "loss = [0.41901350021362305, 0.3219231963157654, 0.29059866070747375, 0.2391507625579834, 0.22189153730869293, 0.1939520537853241, 0.17595382034778595, 0.17593471705913544, 0.17493027448654175, 0.1504407674074173]\n",
      "iteration 42\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=801, total rewards=-0.047328244275442105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-42-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2799\n",
      "best total reward =  [-0.0035087719297035302, -0.0031746031745331915, 14.814814814813758]\n",
      "loss = [0.5184290409088135, 0.3391527235507965, 0.2780553698539734, 0.5514646768569946, 0.2641904056072235, 0.2500668168067932, 0.21785615384578705, 0.1937199831008911, 0.21778850257396698, 0.1849837750196457]\n",
      "iteration 43\n",
      "epsilon=0.724527376459317, episode length=610, total rewards=-0.031297709923628875\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2608\n",
      "best total reward =  [-0.0035087719297035302, -0.0031746031745331915, 14.814814814813758]\n",
      "loss = [0.43638405203819275, 0.3144887089729309, 0.23865336179733276, 0.23739075660705566, 0.19749824702739716, 0.17612534761428833, 0.1677696853876114, 0.1628779172897339, 0.1520271897315979, 0.13730217516422272]\n",
      "iteration 44\n",
      "epsilon=0.7192821026947238, episode length=735, total rewards=-0.07058823529434588\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2733\n",
      "best total reward =  [-0.0035087719297035302, -0.0031746031745331915, 14.814814814813758]\n",
      "loss = [0.43621042370796204, 0.30646389722824097, 0.26651856303215027, 0.21535678207874298, 0.19393672049045563, 0.17429731786251068, 0.17467385530471802, 0.1612340807914734, 0.15024280548095703, 0.15179039537906647]\n",
      "iteration 45\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=176, total rewards=-0.09436619718305228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-45-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon=0.7140892816677766, episode length=626, total rewards=-0.004075235109685965\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2800\n",
      "best total reward =  [-0.0035087719297035302, -0.0031746031745331915, 14.814814814813758]\n",
      "loss = [0.4386675953865051, 0.30856162309646606, 0.2607424259185791, 0.21739815175533295, 0.20892390608787537, 0.18327337503433228, 0.29377374053001404, 0.14934943616390228, 0.15246066451072693, 0.14797236025333405]\n",
      "iteration 46\n",
      "epsilon=0.708948388851099, episode length=157, total rewards=-0.051968503936985266\n",
      "epsilon=0.708948388851099, episode length=999, total rewards=33.82899628252722\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=3154\n",
      "best total reward =  [-0.0031746031745331915, 14.814814814813758, 33.82899628252722]\n",
      "loss = [0.6406534910202026, 0.4101640582084656, 0.3519234359264374, 0.3139306902885437, 0.2786990702152252, 0.2501019835472107, 0.2353590875864029, 0.19916562736034393, 0.18539586663246155, 0.18553222715854645]\n",
      "iteration 47\n",
      "epsilon=0.7038589049625881, episode length=726, total rewards=-0.09273927392750747\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2724\n",
      "best total reward =  [-0.0031746031745331915, 14.814814814813758, 33.82899628252722]\n",
      "loss = [0.45942223072052, 0.36959490180015564, 0.28332051634788513, 0.2402833104133606, 0.22086825966835022, 0.2057884931564331, 0.1897510141134262, 0.17305868864059448, 0.16674111783504486, 0.15711893141269684]\n",
      "iteration 48\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=718, total rewards=-0.004575163399217902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-48-model08.hd5 [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 56.2 MiB/ 56.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/56.2 MiB.                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2716\n",
      "best total reward =  [-0.0031746031745331915, 14.814814814813758, 33.82899628252722]\n",
      "loss = [0.5421455502510071, 0.39488789439201355, 0.3021458089351654, 0.33136940002441406, 0.2553878724575043, 0.23430569469928741, 0.21284975111484528, 0.20815305411815643, 0.18947002291679382, 0.18624867498874664]\n",
      "iteration 49\n",
      "epsilon=0.6938321127538326, episode length=352, total rewards=-0.043589743589682345\n",
      "epsilon=0.6938321127538326, episode length=626, total rewards=-0.013432835820880146\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2976\n",
      "best total reward =  [-0.0031746031745331915, 14.814814814813758, 33.82899628252722]\n"
     ]
    }
   ],
   "source": [
    "train(env, q_value, epsilon=1.0, checkpoint=0)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
