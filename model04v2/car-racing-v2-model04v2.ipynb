{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8eea6db-85c6-41ec-86e6-c33876b5cd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:23: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:24: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:25: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:28: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  if hasattr(pil_image, 'HAMMING'):\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:30: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  if hasattr(pil_image, 'BOX'):\n",
      "/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  if hasattr(pil_image, 'LANCZOS'):\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import copy, random, os, subprocess\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b986a31-fe27-454a-b700-5899f7b4cb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://etsuji-car-racing-v2-model04v2/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'etsuji-car-racing-v2-model04v2' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n",
      "gs://etsuji-car-racing-v2-model04v2/model04v2/\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'gs://etsuji-car-racing-v2-model04v2'\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "!gsutil mb -c regional -l us-west1 $BUCKET\n",
    "!gsutil ls $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a539d906-85d3-487e-a0d9-c111e8abbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model\n",
    "class QValue:\n",
    "    def __init__(self):\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        cnn_input = layers.Input(shape=(96, 96, 6), name='cnn_input')\n",
    "        cnn1 = layers.Conv2D(32, (5, 5), padding='same',\n",
    "                         use_bias=True, activation='relu',\n",
    "                        name='cnn1')(cnn_input)\n",
    "        pool1 = layers.MaxPooling2D((2, 2), name='pool1')(cnn1)\n",
    "        cnn2 = layers.Conv2D(64, (5, 5), padding='same',\n",
    "                         use_bias=True, activation='relu',\n",
    "                        name='cnn2')(pool1)\n",
    "        pool2 = layers.MaxPooling2D((2, 2), name='pool2')(cnn2)\n",
    "\n",
    "        cnn_flatten = layers.Flatten(name='flatten')(pool2)\n",
    "        action_input = layers.Input(shape=(5,), name='action_input')\n",
    "        combined = layers.concatenate([cnn_flatten, action_input], name='concat')\n",
    "        hidden1 = layers.Dense(1024, activation='relu', name='dense1')(combined)\n",
    "        hidden2 = layers.Dense(512, activation='relu', name='dense2')(hidden1)\n",
    "        q_value = layers.Dense(1, name='output')(hidden2)\n",
    "\n",
    "        model = models.Model(inputs=[cnn_input, action_input], outputs=q_value)\n",
    "        model.compile(loss='mse')\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        states = []\n",
    "        actions = []\n",
    "        for a in range(5):\n",
    "            states.append(np.array(state))\n",
    "            action_onehot = np.zeros(5)\n",
    "            action_onehot[a] = 1\n",
    "            actions.append(action_onehot)\n",
    "  \n",
    "        q_values = self.model.predict([np.array(states), np.array(actions)])\n",
    "        optimal_action = np.argmax(q_values)\n",
    "        return optimal_action, q_values[optimal_action][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db3f866-7954-4ed8-b413-edc8726dfc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_frames(o0, o1):\n",
    "    return np.r_[o0.transpose(), o1.transpose()].transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e2758d-6498-41a9-af72-ee0f359fb94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode(environ, q_value, epsilon):\n",
    "    episode = []\n",
    "    o0 = environ.reset()\n",
    "    o1 = copy.deepcopy(o0)\n",
    "    total_r = 0\n",
    "\n",
    "    if epsilon > 0:\n",
    "        keep_count = 1\n",
    "    else:\n",
    "        keep_count = 1\n",
    "\n",
    "    c = 0\n",
    "    while True:\n",
    "        if c % keep_count == 0: # get new action\n",
    "            if np.random.random() < epsilon:\n",
    "                a = np.random.randint(5)\n",
    "            else:\n",
    "                a, _ = q_value.get_action(join_frames(o0, o1))\n",
    "        c += 1\n",
    "        o_new, r, done, inf = environ.step(a)                \n",
    "        total_r += r\n",
    "\n",
    "        if total_r < 0:\n",
    "            done = 1\n",
    "\n",
    "        if done:\n",
    "            if total_r > 990 or r < -99:\n",
    "                episode.append((join_frames(o0, o1), a, r, None))\n",
    "            break\n",
    "        else:\n",
    "            episode.append((join_frames(o0, o1), a, r, join_frames(o1, o_new)))\n",
    "        o0, o1 = o1, o_new\n",
    "\n",
    "    return episode, total_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a401e5d9-9703-426e-957d-92cda5a7c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(environ, q_value, epsilon, checkpoint=0):\n",
    "    if checkpoint > 0:\n",
    "        filename = 'car-racing-v2-model04v2-{}.hd5'.format(checkpoint)\n",
    "        subprocess.run(['gsutil', 'cp', '{}/model04v2/{}'.format(BUCKET, filename), './'])\n",
    "        print('load model {}'.format(filename))\n",
    "        q_value.model = models.load_model(filename)\n",
    "        os.remove(filename)\n",
    "\n",
    "    experience = []\n",
    "    good_experience = []\n",
    "    best_r = [-100, -100, -100]\n",
    "\n",
    "    for n in range(checkpoint + 1, checkpoint + 1000):\n",
    "        print('iteration {}'.format(n))\n",
    "\n",
    "        total_len = 0\n",
    "        if n % 3 == 0:\n",
    "            print('Testing the current performance...')\n",
    "            episode, total_r = get_episode(environ, q_value, epsilon=0)\n",
    "            print('epsilon={}, episode length={}, total rewards={}'.format(0, len(episode), total_r))\n",
    "            with open('result.txt', 'a') as f:\n",
    "                f.write('{},{},{},{}\\n'.format(n, epsilon, len(episode), total_r))\n",
    "            filename = 'car-racing-v2-model04v2-{}.hd5'.format(n)\n",
    "            q_value.model.save(filename, save_format='h5')\n",
    "            subprocess.run(['gsutil', '-m', 'cp',\n",
    "                            '{}'.format(filename), '{}/model04v2/'.format(BUCKET)])\n",
    "            os.remove(filename)\n",
    "            total_len += len(episode)\n",
    "            continue\n",
    "\n",
    "        while total_len < 500:\n",
    "            episode, total_r = get_episode(environ, q_value, epsilon)\n",
    "            print('epsilon={}, episode length={}, total rewards={}'.format(epsilon, len(episode), total_r))\n",
    "            total_len += len(episode)\n",
    "            experience += episode\n",
    "\n",
    "            # ベスト3のエピソードを別枠に保存\n",
    "            if total_r > min(best_r):\n",
    "                # Keep top 3 episodes\n",
    "                best_r = best_r[1:] + [total_r]\n",
    "                good_experience += episode\n",
    "                if len(good_experience) > 999 * 3:\n",
    "                    good_experience = good_experience[-333 * 3:]\n",
    "\n",
    "        # Need enough examples to avoid the inital catastrophic forgetting.\n",
    "        if len(experience) < 999 * 5:\n",
    "            continue\n",
    "\n",
    "        if len(experience) > 999 * 5: # remember last 5 iterations\n",
    "            experience = experience[-999 * 5:]\n",
    "\n",
    "        #epsilon = (epsilon - 0.2) * 0.99 + 0.2\n",
    "        epsilon = (epsilon - 0.1) * 0.99 + 0.1\n",
    "\n",
    "        print('Training the model...')\n",
    "        # 直近のデータ + 過去のデータ（サンプリング）で学習\n",
    "        latest_experience = experience[-total_len:]\n",
    "        past_experience = experience[:-total_len]\n",
    "        examples = latest_experience + \\\n",
    "            random.sample(past_experience, min(len(past_experience), 999)) + \\\n",
    "            random.sample(good_experience, min(len(good_experience), 999))\n",
    "        \n",
    "        # show some statistics\n",
    "        print('experience length={}'.format(len(experience)))\n",
    "        print('number of examples={}'.format(len(examples)))\n",
    "        print('best total reward = ', best_r)\n",
    "        np.random.shuffle(examples)\n",
    "                        \n",
    "        states, actions, labels = [], [], []\n",
    "        for state, a, r, state_new in examples:\n",
    "            states.append(np.array(state))\n",
    "\n",
    "            action_onehot = np.zeros(5)\n",
    "            action_onehot[a] = 1\n",
    "            actions.append(action_onehot)\n",
    "            \n",
    "            if state_new is None:   # Terminal state\n",
    "                q_new = 0\n",
    "            else:\n",
    "                _, q_new = q_value.get_action(state_new)\n",
    "            labels.append(np.array(r + q_new))\n",
    "\n",
    "        hist = q_value.model.fit(\n",
    "            [np.array(states), np.array(actions)], np.array(labels),\n",
    "            batch_size=50, epochs=10, verbose=0)\n",
    "        print('loss = {}'.format(hist.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c407f1a-ef5f-4569-bdcd-2d6197a78c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/opt/conda/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "2022-07-28 04:15:11.232962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " cnn_input (InputLayer)         [(None, 96, 96, 6)]  0           []                               \n",
      "                                                                                                  \n",
      " cnn1 (Conv2D)                  (None, 96, 96, 32)   4832        ['cnn_input[0][0]']              \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 48, 48, 32)   0           ['cnn1[0][0]']                   \n",
      "                                                                                                  \n",
      " cnn2 (Conv2D)                  (None, 48, 48, 64)   51264       ['pool1[0][0]']                  \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 24, 24, 64)   0           ['cnn2[0][0]']                   \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 36864)        0           ['pool2[0][0]']                  \n",
      "                                                                                                  \n",
      " action_input (InputLayer)      [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " concat (Concatenate)           (None, 36869)        0           ['flatten[0][0]',                \n",
      "                                                                  'action_input[0][0]']           \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 1024)         37754880    ['concat[0][0]']                 \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 512)          524800      ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            513         ['dense2[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,336,289\n",
      "Trainable params: 38,336,289\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 04:15:11.245000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 04:15:11.246014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 04:15:11.249064: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-28 04:15:11.249633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 04:15:11.250910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 04:15:11.251950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 04:15:11.777836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 04:15:11.779012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 04:15:11.780003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 04:15:11.780849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15419 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v2\", continuous=False)\n",
    "q_value = QValue()\n",
    "q_value.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "236dd53e-6cdd-46ec-97ac-4f548202013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://etsuji-car-racing-v2-model04/model04/car-racing-v2-model04-351.hd5...\n",
      "| [1 files][292.5 MiB/292.5 MiB]                                                \n",
      "Operation completed over 1 objects/292.5 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://etsuji-car-racing-v2-model04/model04/car-racing-v2-model04-351.hd5 ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b90313-9439-4b91-aabb-de494066d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_value.model = models.load_model('car-racing-v2-model04-351.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad96c84-0beb-4d87-8f78-e18aeab5bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 04:15:19.540026: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon=0.3, episode length=999, total rewards=334.92063492063284\n",
      "iteration 2\n",
      "epsilon=0.3, episode length=999, total rewards=259.1549295774689\n",
      "iteration 3\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=999, total rewards=750.5747126436667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-model04v2-3.hd5 [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/ [1/1 files][292.5 MiB/292.5 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/292.5 MiB.                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 4\n",
      "epsilon=0.3, episode length=999, total rewards=255.07246376811509\n",
      "iteration 5\n",
      "epsilon=0.3, episode length=999, total rewards=185.71428571428956\n",
      "iteration 6\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=999, total rewards=632.6732673267219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-model04v2-6.hd5 [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "- [1/1 files][292.5 MiB/292.5 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/292.5 MiB.                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 7\n",
      "epsilon=0.3, episode length=999, total rewards=211.2582781456983\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2997\n",
      "best total reward =  [334.92063492063284, 259.1549295774689, 255.07246376811509]\n",
      "loss = [6.191128730773926, 3.2850067615509033, 3.165754556655884, 2.596569299697876, 2.4409754276275635, 2.2982587814331055, 2.2565903663635254, 1.9980108737945557, 2.0028154850006104, 1.8345237970352173]\n",
      "iteration 8\n",
      "epsilon=0.298, episode length=999, total rewards=378.0876494023851\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2997\n",
      "best total reward =  [259.1549295774689, 255.07246376811509, 378.0876494023851]\n",
      "loss = [4.0332207679748535, 2.8116612434387207, 2.586707353591919, 2.24554443359375, 2.123455286026001, 1.8113088607788086, 1.767446517944336, 1.6499706506729126, 1.427217960357666, 1.4644793272018433]\n",
      "iteration 9\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=999, total rewards=297.1119133573887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-model04v2-9.hd5 [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/ [1/1 files][292.5 MiB/292.5 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/292.5 MiB.                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10\n",
      "epsilon=0.29601999999999995, episode length=999, total rewards=200.69930069930217\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2997\n",
      "best total reward =  [259.1549295774689, 255.07246376811509, 378.0876494023851]\n",
      "loss = [3.5345206260681152, 2.736424684524536, 2.3548033237457275, 2.366656541824341, 2.151902675628662, 1.8828498125076294, 1.893627405166626, 1.7918059825897217, 1.908003330230713, 1.505308985710144]\n",
      "iteration 11\n",
      "epsilon=0.2940598, episode length=498, total rewards=14.896273291927344\n",
      "epsilon=0.2940598, episode length=999, total rewards=200.6535947712449\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=3495\n",
      "best total reward =  [259.1549295774689, 255.07246376811509, 378.0876494023851]\n",
      "loss = [10.679101943969727, 8.099839210510254, 6.551080703735352, 6.313767433166504, 5.661108493804932, 5.150407314300537, 4.694507122039795, 4.060843467712402, 3.460689067840576, 2.846008062362671]\n",
      "iteration 12\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=999, total rewards=237.66233766233415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-model04v2-12.hd5 [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "- [1/1 files][292.5 MiB/292.5 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/292.5 MiB.                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 13\n",
      "epsilon=0.29211920199999997, episode length=999, total rewards=273.23943661972027\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2997\n",
      "best total reward =  [255.07246376811509, 378.0876494023851, 273.23943661972027]\n",
      "loss = [3.5307388305664062, 2.5795435905456543, 2.2319986820220947, 2.1156082153320312, 1.8708524703979492, 1.7658147811889648, 1.5781450271606445, 8.88652229309082, 1.2358659505844116, 1.7786980867385864]\n",
      "iteration 14\n",
      "epsilon=0.29019800998, episode length=999, total rewards=340.94488188975794\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2997\n",
      "best total reward =  [378.0876494023851, 273.23943661972027, 340.94488188975794]\n",
      "loss = [3.7249019145965576, 2.6335253715515137, 2.4930052757263184, 2.134589910507202, 1.9162776470184326, 1.8154079914093018, 1.6538054943084717, 1.7192270755767822, 1.4830487966537476, 1.4555732011795044]\n",
      "iteration 15\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=999, total rewards=281.27090301003517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://car-racing-v2-model04v2-15.hd5 [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "- [1/1 files][292.5 MiB/292.5 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/292.5 MiB.                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 16\n",
      "epsilon=0.2882960298802, episode length=999, total rewards=251.72413793103803\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2997\n",
      "best total reward =  [378.0876494023851, 273.23943661972027, 340.94488188975794]\n",
      "loss = [3.6817383766174316, 6.933650493621826, 2.3001656532287598, 2.2819108963012695, 2.1366336345672607, 1.9897379875183105, 2.0302510261535645, 1.736586332321167, 1.6495081186294556, 1.5896267890930176]\n",
      "iteration 17\n",
      "epsilon=0.286413069581398, episode length=999, total rewards=39.28571428571611\n",
      "Training the model...\n",
      "experience length=4995\n",
      "number of examples=2997\n",
      "best total reward =  [378.0876494023851, 273.23943661972027, 340.94488188975794]\n",
      "loss = [2.782606601715088, 2.205042600631714, 5.346073627471924, 1.4071722030639648, 1.5357848405838013, 1.3847483396530151, 1.3282179832458496, 1.3137636184692383, 3.8869869709014893, 1.137036681175232]\n",
      "iteration 18\n",
      "Testing the current performance...\n",
      "epsilon=0, episode length=999, total rewards=467.7419354838583\n"
     ]
    }
   ],
   "source": [
    "train(env, q_value, epsilon=0.3, checkpoint=0)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
